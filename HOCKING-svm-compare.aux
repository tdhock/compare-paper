\relax 
\citation{learning-to-rank}
\citation{ranksvm}
\citation{rank-with-ties}
\citation{davidson-ties}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}}
\newlabel{eq:z}{{1}{2}}
\newlabel{eq:min_c}{{2}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related work}{2}}
\newlabel{sec:related}{{2}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Comparison and ranking problems}{2}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces  Comparison (this work) is similar to previous work on ranking and classification with reject option.}}{2}}
\newlabel{tab:related}{{1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Geometric interpretation. \textbf  {Top}: input feature pairs $\mathbf  x_i,\mathbf  x_i'\in \mathbb  R^p$ are segments for $y_i=0$ and arrows for $y_i\in \{-1,1\}$. The level curves of the ranking function $r(\mathbf  x)=||\mathbf  x||_2^2$ are grey, and differences $|r(\mathbf  x')-r(\mathbf  x)|\leq 1$ are considered insignificant ($y_i=0$). \textbf  {Middle}: in the enlarged feature space, the ranking function is linear: $r(\mathbf  x)=\mathbf  w^\intercal \Phi (\mathbf  x)$. \textbf  {Bottom}: two symmetric hyperplanes $\mathbf  w^\intercal [\Phi (\mathbf  x_i')-\Phi (\mathbf  x_i)]\in \{-1,1\}$ are used to classify the difference vectors.}}{3}}
\newlabel{fig:norm-data}{{1}{3}}
\citation{object-ranking-methods,learning-to-rank}
\citation{trueskill}
\citation{GLICKO}
\citation{ranksvm}
\citation{rank-with-ties}
\citation{ordinal}
\citation{sv-survival}
\citation{ranksvm}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}SVMrank for comparing}{4}}
\newlabel{sec:svmrank}{{2.2}{4}}
\newlabel{eq:svmrank}{{3}{4}}
\newlabel{eq:threshold}{{4}{4}}
\newlabel{eq:compare_general}{{5}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Support vector comparison machines}{5}}
\newlabel{sec:svm-compare}{{3}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}LP and QP for separable data}{5}}
\newlabel{sec:lp-qp}{{3.1}{5}}
\newlabel{eq:max-margin-lp}{{7}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The separable LP and QP comparison problems. \textbf  {Left}: the difference vectors $\mathbf  x'-\mathbf  x$ of the original data and the optimal solution to the LP (7\hbox {}). \textbf  {Middle}: for the unscaled flipped data $\mathbf  {\mathaccentV {tilde}07Ex'}-\mathbf  { \mathaccentV {tilde}07Ex}$ (8\hbox {}), the LP is not the same as the QP (9\hbox {}). \textbf  {Right}: in these scaled data, the QP is equivalent to the LP.}}{5}}
\newlabel{fig:hard-margin}{{2}{5}}
\citation{libsvm}
\newlabel{eq:tilde}{{8}{6}}
\newlabel{eq:max-margin-qp-tilde}{{9}{6}}
\newlabel{lemma:feasible}{{1}{6}}
\newlabel{eq:dec-boundary-rank}{{10}{6}}
\newlabel{eq:margin-rank}{{11}{6}}
\newlabel{eq:max-margin-qp}{{12}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Kernelized QP for non-separable data}{7}}
\newlabel{sec:kernelized-qp}{{3.2}{7}}
\newlabel{eq:kernelized_r}{{13}{7}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces SVMcompare}}{7}}
\newlabel{alg:SVMcompare}{{1}{7}}
\citation{libsvm}
\citation{kernlab}
\citation{ranksvm}
\newlabel{eq:lagrangian}{{16}{8}}
\newlabel{eq:stationarity}{{17}{8}}
\newlabel{eq:svm-dual}{{18}{8}}
\newlabel{eq:r_sv}{{19}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{8}}
\newlabel{sec:results}{{4}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Simulation: squared norms in 2D}{9}}
\newlabel{sec:simulations}{{4.1}{9}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces  Summary of how the different algorithms use the input pairs to learn the ranking function $r$. Equality $y_i=0$ pairs are shown as --- segments and inequality $y_i\in \{-1,1\}$ pairs are shown as $\rightarrow $ arrows. For example, the rank2 algorithm converts each input equality pair to two opposite-facing inequality pairs.}}{9}}
\newlabel{tab:models}{{2}{9}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces We use area under the ROC curve to evaluate predictions $\mathaccentV {hat}05Ey$ given the true label $y$. False positives (FP) occur when predicting a significant difference $\mathaccentV {hat}05Ey\in \{-1,1\}$ when there is none $y=0$. False Negatives (FN) occur when a labeled difference $y\in \{-1,1\}$ is incorrectly predicted.}}{9}}
\newlabel{tab:evaluation}{{3}{9}}
\citation{object-ranking-methods}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Application to a simulated pattern $r(\mathbf  x)=||\mathbf  x||_1^2$ where $\mathbf  x\in \mathbb  R^2$. \textbf  {Left}: the training data are $n=100$ pairs, half equality (segments indicate two points of equal rank), and half inequality (arrows point to the higher rank). \textbf  {Others}: level curves of the learned ranking functions. The rank model does not directly model the equality pairs, so the rank2 and compare models recover the true pattern better.}}{10}}
\newlabel{fig:norm-level-curves}{{3}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Test error for 3 different simulated patterns $r(\mathbf  x)$ where $\mathbf  x\in \mathbb  R^2$ and one real sushi data set where $\mathbf  x\in \mathbb  R^{14}$. We randomly generated data sets with $\rho =1/2$ equality and 1/2 inequality pairs, then plotted test error as a function of data set size $n$ (a vertical line shows the data set which was used in Figure\nobreakspace  {}3\hbox {}). Lines show mean and shaded bands show standard deviation over 4 test sets.}}{10}}
\newlabel{fig:simulation-samples}{{4}{10}}
\citation{elo_score}
\citation{GLICKO}
\citation{play-raitings}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Area under the ROC curve (AUC) for 3 different simulated patterns $r(\mathbf  x)$ where $\mathbf  x\in \mathbb  R^2$ and one real sushi data set where $\mathbf  x\in \mathbb  R^{14}$. For each data set we picked $n=400$ pairs, varying the proportion $\rho $ of equality pairs. We plot mean and standard deviation of AUC over 4 test sets.}}{11}}
\newlabel{fig:auc}{{5}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Learning to rank sushi data}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Chess data}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusions and future work}{12}}
\newlabel{sec:conclusions}{{5}{12}}
\bibstyle{abbrvnat}
\bibdata{refs}
\bibcite{libsvm}{{1}{2011}{{Chang and Lin}}{{}}}
\bibcite{ordinal}{{2}{2005}{{Chu and Keerthi}}{{}}}
\bibcite{davidson-ties}{{3}{1970}{{Davidson}}{{}}}
\bibcite{elo_score}{{4}{1978}{{Elo}}{{}}}
\bibcite{GLICKO}{{5}{1999}{{Glickman}}{{}}}
\bibcite{trueskill}{{6}{2006}{{Herbrich et~al.}}{{Herbrich, Minka, and Graepel}}}
\bibcite{ranksvm}{{7}{2002}{{Joachims}}{{}}}
\bibcite{object-ranking-methods}{{8}{2010}{{Kamishima et~al.}}{{Kamishima, Kazawa, and Akaho}}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Test AUC for each model used after training on the first 4 months of match data in the 8 different 12-month periods. All SVM model AUCs are shown in addition to AUC of the ELO, Glicko scores and baseline. The plots in blue show AUC from model using only ELO and Glicko features and plots in red are AUC values from models using all computed features.}}{13}}
\newlabel{fig2}{{6}{13}}
\bibcite{kernlab}{{9}{2004}{{Karatzoglou et~al.}}{{Karatzoglou, Smola, Hornik, and Zeileis}}}
\bibcite{learning-to-rank}{{10}{2011}{{Li}}{{}}}
\bibcite{play-raitings}{{11}{2016}{{Stephenson and Sonas}}{{}}}
\bibcite{sv-survival}{{12}{2011}{{Van~Belle et~al.}}{{Van~Belle, Pelckmans, Van~Huffel, and Suykens}}}
\bibcite{rank-with-ties}{{13}{2008}{{Zhou et~al.}}{{Zhou, Xue, Zha, and Yu}}}
